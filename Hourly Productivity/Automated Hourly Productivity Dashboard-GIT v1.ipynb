{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering for Hourly Productivity Dashboard\n",
    "\n",
    "- Step 1: Collecting hourly datas (product info, time data, pick details) from readonly db\n",
    "- Step 2: Transforming datas into daily and hourly format\n",
    "- Step 3: Uploading transformed datas into staging db\n",
    "- Step 4: Scheduling to perform the task in every hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import create_engine\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter Date Time\n",
    "datetime_format = '%Y-%m-%d %H:%M:%S'\n",
    "#start_date='2021-03-25 09:00:00'\n",
    "#end_date='2021-03-26 08:59:59'\n",
    "#start_date='2021-04-06 09:00:00'\n",
    "#end_date='2021-04-07 08:59:59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProductDeatils\n",
    "ProductDetailsQuery=('''\n",
    "select productid, brandid, productcatid, subcatid\n",
    "from (\n",
    "select productid, brandid, productcatid, subcatid \n",
    ",row_number()over (partition by productid order by subcatid) as rno\n",
    "from orderworkflow.fc_productdetails\n",
    ") unique_productid\n",
    "where rno=1\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting product details exclusively\n",
    "def get_product_detail():\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"13.234.208.5\",\n",
    "        database=\"india_reportsdata\",\n",
    "        user=\"username\",\n",
    "        password=\"password\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    df_product=pd.read_sql(ProductDetailsQuery,conn)\n",
    "    #print(\"--- {} seconds  in get_product_data---\".format ((time.time() - start_time)))\n",
    "    \n",
    "    return df_product;\n",
    "    #df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_query=('''\n",
    "SELECT emailaddress, status,  actiontime, logid \n",
    "    , 'whracks10' as warehouse\n",
    "    , CASE When modulename in ('wave_picking', 'orderbasepicking', 'b2c_orderbasepicking', 'b2b_orderbasepicking'\n",
    "\t\t\t\t\t\t\t   , 'mark_bin_close', 'rack_wise_wave_picking') Then 'Picking'\n",
    "           When modulename in ('qc_shipping', 'qc-shipping') Then 'QC'\n",
    "           When modulename in ('b2c_pick_completed_orders', 'b2c_not_found_list') then 'ConsoPicking'\n",
    "           When modulename in ('b2c_consolidate_orders', 'b2b_consolidate_orders', 'b2c_add_excess_items', \n",
    "\t\t\t\t\t\t\t 'b2b_add_excess_items', 'b2b_consolidate_orders_b2b') then 'ConsoRacking'\n",
    "           When modulename in ('bin/box_packing','b2b_packing') then 'Packing'\n",
    "           Else 'Others' End as process\n",
    "  \t,lag(status) OVER (Partition by emailaddress ORDER BY logid) as prev_to\n",
    "\tFROM whracks10.userworkdetails_log\n",
    "\tWhere actiontime between '2020-11-05 00:00:00' and '2020-11-05 11:59:59'\n",
    "    AND status in ('in', 'out') \n",
    "\tAND modulename in ('wave_picking', 'orderbasepicking', 'b2c_orderbasepicking', 'b2b_orderbasepicking'\n",
    "\t\t\t\t\t\t\t   , 'mark_bin_close', 'rack_wise_wave_picking'\n",
    "                        ,'qc_shipping', 'qc-shipping'\n",
    "                        ,'b2c_pick_completed_orders', 'b2c_not_found_list'\n",
    "                        ,'b2c_consolidate_orders', 'b2b_consolidate_orders', 'b2c_add_excess_items', \n",
    "\t\t\t\t\t\t\t 'b2b_add_excess_items', 'b2b_consolidate_orders_b2b'\n",
    "                        ,'bin/box_packing','b2b_packing')\n",
    "\tOrder by process, emailaddress, logid\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime():\n",
    "      #StartDate\n",
    "    #Establish Connecttion\n",
    "    conn1 = psycopg2.connect(\n",
    "        host=\"13.232.130.170\",\n",
    "        database=\"whracks2\",\n",
    "        user=\"username\",\n",
    "        password=\"password\")\n",
    "    \n",
    "    df=pd.read_sql('''SELECT max(timestamp) FROM \"Master Hourly Productivity Data\" ''',conn1)\n",
    "    tm=df.iloc[0]['max']\n",
    "    tmm=tm + datetime.timedelta(hours = 1)\n",
    "    start_time = datetime.datetime.strptime(str(tmm), '%Y-%m-%d %H:%M:%S')\n",
    "    start_date=str(start_time)\n",
    "    \n",
    "    #End date\n",
    "    end_date=datetime.datetime.now()\n",
    "    end_date=datetime.datetime.strptime(str(end_date),'%Y-%m-%d %H:%M:%S.%f')\\\n",
    "                 .replace(minute=0,second=0,microsecond=0)\n",
    "    end_date=end_date-datetime.timedelta(seconds = 1)\n",
    "    end_date=str(end_date)\n",
    "    \n",
    "    return start_date,end_date;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_query(query,warehouse_id, start_date, end_date):\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "            host=\"13.234.208.5\",\n",
    "            database=\"india_reportsdata\",\n",
    "            user=\"username\",\n",
    "            password=\"password\")\n",
    "    \n",
    "    whracks='whracks'+warehouse_id\n",
    "    whracksarchive='whracksarchive'+warehouse_id\n",
    "    result=query.replace('2020-11-05 00:00:00',start_date)\n",
    "    result=result.replace('2020-11-05 11:59:59',end_date)\n",
    "    result=result.replace('whracks10',whracks)\n",
    "    result=result.replace('whracksarchive10',whracksarchive)\n",
    "    result=pd.read_sql(result,conn)\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_data(start_date,end_date):    \n",
    "\n",
    "    #Get Time Data\n",
    "    wh=['2','7','9','10','11','12']\n",
    "    df=pd.DataFrame()\n",
    "    start_time = time.time() #To know execution time\n",
    "    \n",
    "    start_date,end_date=start_date,end_date\n",
    "\n",
    "    for wh in wh:\n",
    "        df1=read_query(time_query,wh,start_date,end_date)\n",
    "        df=df.append(df1)\n",
    "        #print(\"--- {} seconds in WH {} get_time_data---\".format ((time.time() - start_time),wh))\n",
    "\n",
    "\n",
    "    #Remove consecutive 'in' 'out'\n",
    "    df=df[df.status!=df.prev_to].drop(['logid','prev_to'],axis=1)\n",
    "\n",
    "    #Create hourly timestamp \n",
    "    df['timestamp']=[datetime.datetime.strptime(str(x),datetime_format)\\\n",
    "                     .replace(minute=0,second=0)\\\n",
    "                    for x in df['actiontime']]\n",
    "\n",
    "    #Calculate in_time out_time in sec\n",
    "    df['diff_in_sec']=df['actiontime']-df['timestamp']\n",
    "    df['diff_in_sec']=(df['actiontime']-df['timestamp']).dt.total_seconds()\n",
    "\n",
    "    #Creating Groupby to calculate total working seconds\n",
    "    time_gb=df.assign(\n",
    "         in_time = np.where(df['status']=='in',df.diff_in_sec,0),\n",
    "         out_time = np.where(df['status']=='out',df.diff_in_sec,0)\n",
    "         ).groupby(['warehouse','process','timestamp','emailaddress']).agg({'in_time':sum, 'out_time':sum}).reset_index()\n",
    "\n",
    "    time_gb['working_sec']=time_gb.out_time-time_gb.in_time\n",
    "\n",
    "    #For negative working_sec need to add time interval\n",
    "    interval_time=3600 #Here its 1 hr ie 3600 sec\n",
    "    time_gb.loc[time_gb.working_sec<0,'working_sec']=[x+interval_time for x in time_gb.working_sec if x<0]\n",
    "\n",
    "    #Drop Unnecessary columns\n",
    "    time_gb.drop(['in_time','out_time'],axis=1,inplace=True)\n",
    "\n",
    "    return time_gb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_detail_query=('''\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Picking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackpickdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracksarchive10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'Picking'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "        \n",
    "UNION ALL\n",
    "\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Picking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackpickdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracks10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'Picking'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_pick_detail_query=('''\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'ConsoPicking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackconsodetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracksarchive10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'ConsoOut'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "        \n",
    "UNION ALL\n",
    "\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Picking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackconsodetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracks10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'ConsoOut'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_rack_detail_query=('''\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'ConsoRacking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackpickdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracksarchive10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'Conso'\n",
    "                    AND taskname in ('B2CExcessRackIn', 'B2BExcessRackIn'\n",
    "\t\t\t\t\t\t\t\t\t , 'B2BConsoRackIn', 'B2CConsoRackIn')\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "        \n",
    "UNION ALL\n",
    "\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Picking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackpickdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracks10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'Conso'\n",
    "                    AND taskname in ('B2CExcessRackIn', 'B2BExcessRackIn'\n",
    "\t\t\t\t\t\t\t\t\t , 'B2BConsoRackIn', 'B2CConsoRackIn')\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC_detail_query=('''\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'QC' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackqcdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracksarchive10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'QCShipping'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "        \n",
    "UNION ALL\n",
    "\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Picking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.orderitemsrackqcdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracks10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'QCShipping'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Packing_detail_query=('''\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Packing' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.packingbinitemdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracksarchive10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'Packing'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "        \n",
    "UNION ALL\n",
    "\n",
    "Select \"emailaddress\",\"businesstype\", \"quantity\", \"processquantity\", \"notfoundquantity\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t             ,productid,lastmodifieddate,'Picking' as process, 'whracks10' as warehouse\n",
    "                 FROM whracksarchive10.packingbinitemdetails\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    WHERE (\"processquantity\" >0 OR \"notfoundquantity\" >0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \ttaskid IN(SELECT distinct \"taskid\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    FROM whracks10.taskmaster\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    WHERE \"tasktype\" = 'Packing'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    AND   (\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    (\"startdate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59' or  \"enddate\" between '2020-11-05 00:00:00' and '2020-11-05 11:59:59')\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                    OR ('2020-11-05 00:00:00' between \"startdate\" and enddate or '2020-11-05 11:59:59' between \"startdate\" and enddate)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                 \t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        \t\t\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" < '2020-11-05 11:59:59'\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "        AND \"lastmodifieddate\" >= '2020-11-05 00:00:00' \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pick_data(start_date,end_date):\n",
    "    #Get Pick Data\n",
    "    wh=['2','7','9','10','11','12']\n",
    "    df=pd.DataFrame()\n",
    "    start_time = time.time() #To know execution time\n",
    "    start_date,end_date=start_date,end_date\n",
    "\n",
    "    for wh in wh:\n",
    "        df1=read_query(pick_detail_query,wh,start_date,end_date)\n",
    "        df=df.append(df1)\n",
    "        #print(\"--- {} seconds in WH {} Picking---\".format ((time.time() - start_time),wh))\n",
    "\n",
    "        df1=read_query(conso_pick_detail_query,wh,start_date,end_date)\n",
    "        df=df.append(df1)\n",
    "        #print(\"--- {} seconds in WH {} ConsoPicking---\".format ((time.time() - start_time),wh))\n",
    "\n",
    "        df1=read_query(conso_rack_detail_query,wh,start_date,end_date)\n",
    "        df=df.append(df1)\n",
    "        #print(\"--- {} seconds in WH {} ConsoRacking---\".format ((time.time() - start_time),wh))\n",
    "\n",
    "        df1=read_query(QC_detail_query,wh,start_date,end_date)\n",
    "        df=df.append(df1)\n",
    "        #print(\"--- {} seconds in WH {} QC---\".format ((time.time() - start_time),wh))\n",
    "\n",
    "        df1=read_query(Packing_detail_query,wh,start_date,end_date)\n",
    "        df=df.append(df1)\n",
    "        #print(\"--- {} seconds in WH {} Packing---\".format ((time.time() - start_time),wh))\n",
    "        \n",
    "    return df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_productivity_rawdata(df_product, time_gb, df):\n",
    "\n",
    "    #Create hourly timestamp \n",
    "    df['timestamp']=[datetime.datetime.strptime(str(x),datetime_format)\\\n",
    "                     .replace(minute=0,second=0)\\\n",
    "                    for x in df['lastmodifieddate']]\n",
    "\n",
    "    #Join Report with productdetails\n",
    "    df= pd.merge(df, df_product, how ='left')\n",
    "\n",
    "    #Creating Groupby to calculate pickdetails\n",
    "    pick_gb=df.assign(\n",
    "        Quantity = df.processquantity,\n",
    "        totalnotfound = df.notfoundquantity,\n",
    "        B2B_Qty = np.where(df['businesstype']=='B2B',df.processquantity,0),\n",
    "        B2C_Qty = np.where(df['businesstype']=='B2C',df.processquantity,0),\n",
    "        BabyGear_Qty= np.where(df['productcatid']=='7',df.processquantity,0),\n",
    "        Consumable_Qty = np.where(df['productcatid']=='999',df.processquantity,0)\n",
    "         ).groupby(['warehouse','process','timestamp','emailaddress']).agg({'Quantity':sum,\n",
    "                                                                            'totalnotfound':sum,\n",
    "                                                                            'B2B_Qty':sum,\n",
    "                                                                            'B2C_Qty':sum,\n",
    "                                                                            'BabyGear_Qty':sum,\n",
    "                                                                            'Consumable_Qty':sum\n",
    "                                                                           }).reset_index()\n",
    "    #pick_gb\n",
    "\n",
    "    #Join  pickdetails with time details\n",
    "    df_final= pd.merge(pick_gb, time_gb, how='left')\n",
    "    #null value in working_sec column should be filled with interval time ie 1 hr\n",
    "    interval_time=3600#in sec\n",
    "    df_final.working_sec.fillna(interval_time,inplace=True)\n",
    "    #Qty having more than 1 picking should be awarded 1 hr\n",
    "    df_final.loc[(df_final.Quantity>0 )& (df_final.working_sec==0),'working_sec']=interval_time\n",
    "\n",
    "    df_final['warehouse']=df_final['warehouse'].replace('whracks2','CHKN')\n",
    "    df_final['warehouse']=df_final['warehouse'].replace('whracks7','BLR')\n",
    "    df_final['warehouse']=df_final['warehouse'].replace('whracks9','HRN')           \n",
    "    df_final['warehouse']=df_final['warehouse'].replace('whracks10','PNQ')\n",
    "    df_final['warehouse']=df_final['warehouse'].replace('whracks11','FRQ') \n",
    "    df_final['warehouse']=df_final['warehouse'].replace('whracks12','INDR')\n",
    "\n",
    "    #Transforming Data into daily and hourly \n",
    "    df=df_final\n",
    "    df['QTY']=df['Quantity']-df['Consumable_Qty']\n",
    "\n",
    "    return df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_report(df):\n",
    "    #Creating Groupby by Hourly Wise\n",
    "    df_hr=df.assign(\n",
    "        QTY = df.Quantity-df.Consumable_Qty).groupby(['warehouse','process','timestamp']).agg({'QTY':sum,\n",
    "                                                                                               'working_sec':sum,\n",
    "                                                                                               'emailaddress':'nunique'               \n",
    "                                                                           }).reset_index()\n",
    "\n",
    "    df_hr['EPH']=df_hr['QTY']/df_hr['working_sec']*3600\n",
    "    df_hr['Distinct_User']=df_hr['emailaddress']\n",
    "    df_hr.drop(['working_sec','emailaddress'],axis=1, inplace=True)\n",
    "\n",
    "    #Daily\n",
    "    df['date'] = pd.to_datetime(df['timestamp']).dt.date\n",
    "\n",
    "    #Creating Groupby by Date Wise\n",
    "    df_dly=df.assign(\n",
    "        QTY = df.Quantity-df.Consumable_Qty).groupby(['warehouse','process','date']).agg({'QTY':sum,\n",
    "                                                                                               'working_sec':sum,\n",
    "                                                                                               'emailaddress':'nunique'               \n",
    "                                                                           }).reset_index()\n",
    "\n",
    "    df_dly['Distinct_User']=df_dly['emailaddress']\n",
    "    df_dly['EPH']=df_dly['QTY']/df_dly['working_sec']*3600\n",
    "    df_dly.drop(['working_sec','emailaddress'],axis=1, inplace=True)\n",
    "    \n",
    "    return df_hr,df_dly;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_productivity_report():\n",
    "    \n",
    "    start_time = time.time() #To know execution time\n",
    "    \n",
    "    start_date,end_date=get_datetime()\n",
    "    print(\"Running Programme for start_date: {} and end_date: {} \".format (start_date,end_date))\n",
    "    df_product=get_product_detail()\n",
    "    time_gb=get_time_data(start_date,end_date)\n",
    "    df=get_pick_data(start_date,end_date)\n",
    "    df=create_productivity_rawdata(df_product,time_gb,df)\n",
    "    df_hr,df_dly=create_final_report(df)\n",
    "    \n",
    "    #Establish Connecttion#This is for staging\n",
    "    engine = create_engine('postgresql://username:password@XX.XXX.XXX.XXX/whracks2')\n",
    "\n",
    "    #Feeding data into database\n",
    "\n",
    "    df_dly.to_sql('Master Daily Productivity Data', engine,if_exists='append',index=False)\n",
    "\n",
    "    df_hr.to_sql('Master Hourly Productivity Data', engine,if_exists='append',index=False)\n",
    "    \n",
    "    print(\"TOTAL EXECUTION TIME: {} seconds \".format ((time.time() - start_time)))\n",
    "    #return df_hr,df_dly;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler\n",
    "#### Main Function - to execute all functions to upload productivity data into staging db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scheduling to perform the task in every hour\n",
    "scheduler = BlockingScheduler()\n",
    "scheduler.add_job(upload_productivity_report, 'interval', hours=1)\n",
    "scheduler.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial\n",
    "#start_date,end_date=get_datetime()\n",
    "#start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
